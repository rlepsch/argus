{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "argus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlepsch/argus/blob/main/argus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flekT6GFDN6m"
      },
      "source": [
        "# <span style=\"color:blue\">REINALDO LEPSCH NETO - TEST FOR ARGUS</span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://movile.blog/introducao-a-spark-usando-o-google-colab/\n",
        "\n",
        "https://ichi.pro/pt/observacoes-sobre-como-salvar-dados-com-spark-3-0-148135666658161\n"
      ],
      "metadata": {
        "id": "6SF1wXYkQ4pR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCCNC64AzBG0"
      },
      "source": [
        "## 2.1 Downloading wget\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e0Eao1K0EYG"
      },
      "source": [
        "#instalando o módulo wget\n",
        "%%capture\n",
        "!pip install -q wget\n",
        "#criando pasta para salvar as bases de dados\n",
        "!mkdir data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j56pVJ2hZ2i5"
      },
      "source": [
        "## 2.2 Downloading the databases as copied to github\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46QzTpLJwfkW",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f264a195-7a61-4a40-9139-23318518bc96"
      },
      "source": [
        "#baixando os dados das tabelas de dimensão\n",
        "import wget\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/rlepsch/argus/main/repo1.csv\"\n",
        "wget.download(url, \"data/repo1.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/rlepsch/argus/main/repo2.csv\"\n",
        "wget.download(url, \"data/repo2.csv\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/rlepsch/argus/main/vhf_code.csv\"\n",
        "wget.download(url, \"data/vhf_code.csv\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/vhf_code.csv'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO16-7-jOioq"
      },
      "source": [
        "# 3 Apache Spark Cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXls3bfoglKW"
      },
      "source": [
        "#instalando Java Runtime Environment (JRE) versão 8\n",
        "%%capture\n",
        "!apt-get remove openjdk*\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a_Yv59zg3gm"
      },
      "source": [
        "#baixando Apache Spark versão 3.0.0\n",
        "%%capture\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop2.7.tgz && rm spark-3.0.0-bin-hadoop2.7.tgz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZpR7NwOh2EB"
      },
      "source": [
        "import os\n",
        "#configurando a variável de ambiente JAVA_HOME\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#configurando a variável de ambiente SPARK_HOME\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oSYOwKljPf5"
      },
      "source": [
        "%%capture\n",
        "#instalando o pacote findspark\n",
        "!pip install -q findspark==1.4.2\n",
        "#instalando o pacote pyspark\n",
        "!pip install -q pyspark==3.0.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zm1pBTEmjp4"
      },
      "source": [
        "#importando o módulo findspark\n",
        "import findspark\n",
        "#carregando a variávels SPARK_HOME na variável dinâmica PYTHONPATH\n",
        "findspark.init()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TxljJ_cwBCy"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"pyspark-notebook\").master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qL9SiR_pQE2"
      },
      "source": [
        "# 4 Preparação dos Dados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "FNR-3dV6oYk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d4df31-a540-4a87-e57b-650257077f7b"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela repo1\n",
        "\n",
        "repo1 = spark.read.csv(path=\"data/repo1.csv\", header=True, sep=\",\")\n",
        "repo1.show(5)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+--------------------+------+---------------------+-------------------+--------------+------------+\n",
            "|vhf_repository_id|vhf_code_id|publication_datetime| value|applies_from_datetime|applies_to_datetime|forward_period|forward_year|\n",
            "+-----------------+-----------+--------------------+------+---------------------+-------------------+--------------+------------+\n",
            "|        184950377|      45747|    15/12/2021 13:23|     2|     15/12/2021 13:22|   15/12/2021 13:23|             2|        2022|\n",
            "|        184950374|      45743|    15/12/2021 13:23|2.0775|     15/12/2021 13:22|   15/12/2021 13:23|             2|        2022|\n",
            "|        184950371|      45745|    15/12/2021 13:23|2.0775|     15/12/2021 13:22|   15/12/2021 13:23|             2|        2022|\n",
            "|        184950368|      45744|    15/12/2021 13:23|2.0776|     15/12/2021 13:22|   15/12/2021 13:23|             2|        2022|\n",
            "|        184950365|      45746|    15/12/2021 13:23|2.0776|     15/12/2021 13:22|   15/12/2021 13:23|             2|        2022|\n",
            "+-----------------+-----------+--------------------+------+---------------------+-------------------+--------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPCF-SyBtuPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e833ccf-196c-4250-b2b4-d2739da2e646"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela repo2\n",
        "\n",
        "repo2 = spark.read.csv(path=\"data/repo2.csv\", header=True, sep=\",\")\n",
        "repo2.show(5)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+--------------------+-----+---------------------+-------------------+--------------+------------+\n",
            "|vhf_repository_id|vhf_code_id|publication_datetime|value|applies_from_datetime|applies_to_datetime|forward_period|forward_year|\n",
            "+-----------------+-----------+--------------------+-----+---------------------+-------------------+--------------+------------+\n",
            "|        184931068|      45691| 15/12/2021 12:38:00|72.65|  15/12/2021 12:37:00|15/12/2021 12:38:00|             4|        2022|\n",
            "|        184931061|      45687| 15/12/2021 12:38:00|12.00|  15/12/2021 12:37:00|15/12/2021 12:38:00|             3|        2022|\n",
            "|        184931059|      45683| 15/12/2021 12:38:00|72.93|  15/12/2021 12:37:00|15/12/2021 12:38:00|             3|        2022|\n",
            "|        184931057|      45685| 15/12/2021 12:38:00|72.91|  15/12/2021 12:37:00|15/12/2021 12:38:00|             3|        2022|\n",
            "|        184931055|      45684| 15/12/2021 12:38:00|72.93|  15/12/2021 12:37:00|15/12/2021 12:38:00|             3|        2022|\n",
            "+-----------------+-----------+--------------------+-----+---------------------+-------------------+--------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3p9dLUKts73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41844620-2b2a-4bde-e83b-c81bb284ade8"
      },
      "source": [
        "#criando e exibindo o DataFrame para a tabela vhf_code\n",
        "\n",
        "vhf_code = spark.read.csv(path=\"data/vhf_code.csv\", header=True, sep=\",\")\n",
        "vhf_code.show(5)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+------------------+-----------+\n",
            "|         description|external_description|   description_short|external_query_str|vhf_code_id|\n",
            "+--------------------+--------------------+--------------------+------------------+-----------+\n",
            "|Brent month 1 1-m...|     Crude Oil Brent|Brent M1 1-min close|             CLOSE|      45678|\n",
            "|Brent month 1 1-m...|     Crude Oil Brent| Brent M1 1-min high|              HIGH|      45679|\n",
            "|Brent month 1 1-m...|     Crude Oil Brent|  Brent M1 1-min low|               LOW|      45680|\n",
            "|Brent month 1 1-m...|     Crude Oil Brent| Brent M1 1-min open|              OPEN|      45681|\n",
            "|Brent month 1 1-m...|     Crude Oil Brent|Brent M1 1-min vo...|            VOLUME|      45682|\n",
            "+--------------------+--------------------+--------------------+------------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB4dFUqHoiaW"
      },
      "source": [
        "#criando as visões temporárias para as tabelas\n",
        "repo1.createOrReplaceTempView(\"repo1\")\n",
        "repo2.createOrReplaceTempView(\"repo2\")\n",
        "vhf_code.createOrReplaceTempView(\"vhf_code\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vhf_code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7cQ9bYbMosj",
        "outputId": "8bd37545-bb2e-43e8-b7af-4d537b82aad7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[description: string, external_description: string, description_short: string, external_query_str: string, vhf_code_id: string]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss0pmgplPAL3"
      },
      "source": [
        "# 5 Execução de Consultas com Foco nas Operações OLAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGMSoyQRoqnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d4e50f8-67e1-4a62-c62e-35d292dbb13d"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT vhf_repository_id\n",
        "FROM repo1 \n",
        "where value > 2\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|vhf_repository_id|\n",
            "+-----------------+\n",
            "|        184950361|\n",
            "|        184950325|\n",
            "|        184950320|\n",
            "|        184950315|\n",
            "|        184950310|\n",
            "|        184950305|\n",
            "|        184950299|\n",
            "|        184950293|\n",
            "|        184950287|\n",
            "|        184950281|\n",
            "|        184950275|\n",
            "|        184950268|\n",
            "|        184950262|\n",
            "|        184950256|\n",
            "|        184950250|\n",
            "|        184950244|\n",
            "|        184950376|\n",
            "|        184950360|\n",
            "|        184950324|\n",
            "|        184950319|\n",
            "+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "( \n",
        "  repo1.write\n",
        "  .mode('append') # or append\n",
        "  #.partitionBy(col_name) # this is optional\n",
        "  .bucketBy(5, 'forward_period') # n is number of buckets\n",
        "  .sortBy('forward_period')\n",
        "  #.format('parquet') # this is optional, parquet is default\n",
        "  .option('path','file:///Users/reinaldolepsch/Downloads')\n",
        "  .saveAsTable('tb_output')\n",
        ")"
      ],
      "metadata": {
        "id": "z74IpVAeI664"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.table('tb_output')"
      ],
      "metadata": {
        "id": "KDmTR3dNPhZN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "SELECT *\n",
        "FROM tb_output \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkozdamhPqwo",
        "outputId": "5f28fb83-0ec8-471b-bed3-05a7b9e4ea5f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------+--------------------+-----+---------------------+-------------------+--------------+------------+\n",
            "|vhf_repository_id|vhf_code_id|publication_datetime|value|applies_from_datetime|applies_to_datetime|forward_period|forward_year|\n",
            "+-----------------+-----------+--------------------+-----+---------------------+-------------------+--------------+------------+\n",
            "|        184950144|      45692|    15/12/2021 13:22|   38|     15/12/2021 13:21|   15/12/2021 13:22|             4|        2022|\n",
            "|        184950138|      45688|    15/12/2021 13:22|72.45|     15/12/2021 13:21|   15/12/2021 13:22|             4|        2022|\n",
            "|        184950132|      45690|    15/12/2021 13:22|72.44|     15/12/2021 13:21|   15/12/2021 13:22|             4|        2022|\n",
            "|        184950126|      45689|    15/12/2021 13:22|72.45|     15/12/2021 13:21|   15/12/2021 13:22|             4|        2022|\n",
            "|        184950120|      45691|    15/12/2021 13:22|72.44|     15/12/2021 13:21|   15/12/2021 13:22|             4|        2022|\n",
            "|        184950143|      45692|    15/12/2021 13:21|   91|     15/12/2021 13:20|   15/12/2021 13:21|             4|        2022|\n",
            "|        184950137|      45688|    15/12/2021 13:21|72.44|     15/12/2021 13:20|   15/12/2021 13:21|             4|        2022|\n",
            "|        184950131|      45690|    15/12/2021 13:21|72.41|     15/12/2021 13:20|   15/12/2021 13:21|             4|        2022|\n",
            "|        184950125|      45689|    15/12/2021 13:21|72.44|     15/12/2021 13:20|   15/12/2021 13:21|             4|        2022|\n",
            "|        184950119|      45691|    15/12/2021 13:21|72.44|     15/12/2021 13:20|   15/12/2021 13:21|             4|        2022|\n",
            "|        184950142|      45692|    15/12/2021 13:20|   11|     15/12/2021 13:19|   15/12/2021 13:20|             4|        2022|\n",
            "|        184950136|      45688|    15/12/2021 13:20|72.45|     15/12/2021 13:19|   15/12/2021 13:20|             4|        2022|\n",
            "|        184950130|      45690|    15/12/2021 13:20|72.44|     15/12/2021 13:19|   15/12/2021 13:20|             4|        2022|\n",
            "|        184950124|      45689|    15/12/2021 13:20|72.47|     15/12/2021 13:19|   15/12/2021 13:20|             4|        2022|\n",
            "|        184950118|      45691|    15/12/2021 13:20|72.46|     15/12/2021 13:19|   15/12/2021 13:20|             4|        2022|\n",
            "|        184950141|      45692|    15/12/2021 13:19|    9|     15/12/2021 13:18|   15/12/2021 13:19|             4|        2022|\n",
            "|        184950135|      45688|    15/12/2021 13:19|72.47|     15/12/2021 13:18|   15/12/2021 13:19|             4|        2022|\n",
            "|        184950129|      45690|    15/12/2021 13:19|72.46|     15/12/2021 13:18|   15/12/2021 13:19|             4|        2022|\n",
            "|        184950123|      45689|    15/12/2021 13:19|72.47|     15/12/2021 13:18|   15/12/2021 13:19|             4|        2022|\n",
            "|        184950117|      45691|    15/12/2021 13:19|72.46|     15/12/2021 13:18|   15/12/2021 13:19|             4|        2022|\n",
            "+-----------------+-----------+--------------------+-----+---------------------+-------------------+--------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AS PROXIMAS CELULAS IR SUBSTITUINDO PELOS CODIGOS SOLICITADOS"
      ],
      "metadata": {
        "id": "fjXdli5jktkT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crCnMYwi7rIm"
      },
      "source": [
        "## 5.2 Operações Drill-Down e Roll-Up\n",
        "\n",
        "**Definição**: Analisam os dados considerando níveis progressivos de agregação.\n",
        "\n",
        "- Drill-down: níveis de agregação progressivamente mais detalhados, ou de menor granularidade.\n",
        "- Roll-up: níveis de agregação progressivamente menos detalhados, ou de maior granularidade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC-qVTVIpyX4"
      },
      "source": [
        "Para ilustrar as operações de drill-down e roll-up, considere a consulta base definida a seguir.\n",
        "\n",
        "**Consulta base:** Qual o valor gasto em salários por ano, considerando cada **semestre**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnaUOx3uow4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263e5e30-6cc9-4f8c-f6aa-12e8844a8b86"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, dataSemestre, ROUND(SUM(salario),2) AS `Valor gasto em salários por semestre`\n",
        "FROM data JOIN pagamento ON data.dataPK = pagamento.dataPK \n",
        "GROUP BY dataAno, dataSemestre\n",
        "ORDER BY dataAno, dataSemestre\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+------------------------------------+\n",
            "|dataAno|dataSemestre|Valor gasto em salários por semestre|\n",
            "+-------+------------+------------------------------------+\n",
            "|   2016|           1|                          2221308.54|\n",
            "|   2016|           2|                          2221308.54|\n",
            "|   2017|           1|                           4887639.9|\n",
            "|   2017|           2|                           4887639.9|\n",
            "|   2018|           1|                           7467763.2|\n",
            "|   2018|           2|                           7467763.2|\n",
            "|   2019|           1|                          9283833.18|\n",
            "|   2019|           2|                          9283833.18|\n",
            "|   2020|           1|                          9283833.18|\n",
            "|   2020|           2|                          9283833.18|\n",
            "+-------+------------+------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PzzQT1Xz-4-"
      },
      "source": [
        "**Exemplo de consulta drill-down:** Qual o valor gasto em salários por ano, considerando cada **trimestre**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8EZJPBSquj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12305f0-dcdf-4ee6-b6ef-37dcbaa98dc6"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, dataTrimestre, ROUND(SUM(salario),2) AS `Valor gasto em salários por trimestre`\n",
        "FROM data JOIN pagamento ON (data.dataPK = pagamento.dataPK) \n",
        "GROUP BY dataAno, dataTrimestre\n",
        "ORDER BY dataAno, dataTrimestre\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+-------------------------------------+\n",
            "|dataAno|dataTrimestre|Valor gasto em salários por trimestre|\n",
            "+-------+-------------+-------------------------------------+\n",
            "|   2016|            1|                           1110654.27|\n",
            "|   2016|            2|                           1110654.27|\n",
            "|   2016|            3|                           1110654.27|\n",
            "|   2016|            4|                           1110654.27|\n",
            "|   2017|            1|                           2443819.95|\n",
            "|   2017|            2|                           2443819.95|\n",
            "|   2017|            3|                           2443819.95|\n",
            "|   2017|            4|                           2443819.95|\n",
            "|   2018|            1|                            3733881.6|\n",
            "|   2018|            2|                            3733881.6|\n",
            "|   2018|            3|                            3733881.6|\n",
            "|   2018|            4|                            3733881.6|\n",
            "|   2019|            1|                           4641916.59|\n",
            "|   2019|            2|                           4641916.59|\n",
            "|   2019|            3|                           4641916.59|\n",
            "|   2019|            4|                           4641916.59|\n",
            "|   2020|            1|                           4641916.59|\n",
            "|   2020|            2|                           4641916.59|\n",
            "|   2020|            3|                           4641916.59|\n",
            "|   2020|            4|                           4641916.59|\n",
            "+-------+-------------+-------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bFWeBr87xpN"
      },
      "source": [
        "**Exemplo de consulta roll-up:** Qual o valor gasto em salários por **ano**?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPKhALIJrllz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3efa69-0370-4e17-a44c-131f01400a67"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, ROUND(SUM(salario),2) AS `Valor gasto em salários por ano`\n",
        "FROM data JOIN pagamento ON (data.dataPK = pagamento.dataPK) \n",
        "GROUP BY dataAno\n",
        "ORDER BY dataAno\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------------------+\n",
            "|dataAno|Valor gasto em salários por ano|\n",
            "+-------+-------------------------------+\n",
            "|   2016|                     4442617.08|\n",
            "|   2017|                      9775279.8|\n",
            "|   2018|                   1.49355264E7|\n",
            "|   2019|                  1.856766636E7|\n",
            "|   2020|                  1.856766636E7|\n",
            "+-------+-------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1kRDhciLQnj"
      },
      "source": [
        "## 5.3 Operação Pivot\n",
        "\n",
        "**Definição:** Reorienta a visão multidimensional dos dados, oferecendo diferentes perspectivas dos mesmos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaXAXkeF1atH"
      },
      "source": [
        "Para ilustrar a operação pivot, considere a consulta base definida a seguir. \n",
        "\n",
        "**Consulta base:**  Qual o valor gasto em salários por ano, considerando cada nível de cargo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiA8yW23o9H5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "647bc167-cb60-4ae3-f56f-4dadba1eb458"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT dataAno, cargoNivel, ROUND(SUM(salario),2) AS `Gastos em Salários`\n",
        "FROM pagamento JOIN data ON pagamento.dataPK = data.dataPK \n",
        "               JOIN cargo ON pagamento.cargoPK = cargo.cargoPK \n",
        "GROUP BY dataAno, cargoNivel\n",
        "ORDER BY dataAno, cargoNivel\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+------------------+\n",
            "|dataAno|cargoNivel|Gastos em Salários|\n",
            "+-------+----------+------------------+\n",
            "|   2016|    JUNIOR|         489456.84|\n",
            "|   2016|     PLENO|        1454152.44|\n",
            "|   2016|    SENIOR|         2499007.8|\n",
            "|   2017|    JUNIOR|         1030642.8|\n",
            "|   2017|     PLENO|        3791593.92|\n",
            "|   2017|    SENIOR|        4953043.08|\n",
            "|   2018|    JUNIOR|         1393282.2|\n",
            "|   2018|     PLENO|        5357227.44|\n",
            "|   2018|    SENIOR|        8185016.76|\n",
            "|   2019|    JUNIOR|        1755714.36|\n",
            "|   2019|     PLENO|        6132228.24|\n",
            "|   2019|    SENIOR|     1.067972376E7|\n",
            "|   2020|    JUNIOR|        1755714.36|\n",
            "|   2020|     PLENO|        6132228.24|\n",
            "|   2020|    SENIOR|     1.067972376E7|\n",
            "+-------+----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPBaswdrLWv6"
      },
      "source": [
        "**Exemplo de consulta pivot:** Qual o valor gasto em salários por nível de cargo, considerando cada ano?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v63e5Yps2CSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58b7f0b-f549-49d9-fd72-8f2bc0a20b1a"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT cargoNivel, dataAno, ROUND(SUM(salario),2) AS `Gastos em Salários`\n",
        "FROM pagamento JOIN data ON pagamento.dataPK = data.dataPK \n",
        "               JOIN cargo ON pagamento.cargoPK = cargo.cargoPK \n",
        "GROUP BY cargoNivel, dataAno\n",
        "ORDER BY cargoNivel, dataAno\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+------------------+\n",
            "|cargoNivel|dataAno|Gastos em Salários|\n",
            "+----------+-------+------------------+\n",
            "|    JUNIOR|   2016|         489456.84|\n",
            "|    JUNIOR|   2017|         1030642.8|\n",
            "|    JUNIOR|   2018|         1393282.2|\n",
            "|    JUNIOR|   2019|        1755714.36|\n",
            "|    JUNIOR|   2020|        1755714.36|\n",
            "|     PLENO|   2016|        1454152.44|\n",
            "|     PLENO|   2017|        3791593.92|\n",
            "|     PLENO|   2018|        5357227.44|\n",
            "|     PLENO|   2019|        6132228.24|\n",
            "|     PLENO|   2020|        6132228.24|\n",
            "|    SENIOR|   2016|         2499007.8|\n",
            "|    SENIOR|   2017|        4953043.08|\n",
            "|    SENIOR|   2018|        8185016.76|\n",
            "|    SENIOR|   2019|     1.067972376E7|\n",
            "|    SENIOR|   2020|     1.067972376E7|\n",
            "+----------+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtJILugUN2K_"
      },
      "source": [
        "## 5.4 Operação Drill-Across\n",
        "\n",
        "**Definição:** Compara medidas numéricas de tabelas de fatos diferentes, utilizando pelo menos uma dimensão em comum. \n",
        "\n",
        "**Exemplo de consulta:** Qual o total gasto com salários e qual o total de receitas recebidas, considerando cada ano?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyoWQDJiIgQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eabfd2e-c676-4e9b-da7c-dbf30c03c8c3"
      },
      "source": [
        "# utilizando a cláusula JOIN ... ON ...\n",
        "query = \"\"\"\n",
        "SELECT anoPag AS `Ano`, ROUND(salario,2) AS `Total Gasto com Salários`, ROUND(receita,2) AS `Total de Receitas Recebidas`\n",
        "FROM ( SELECT dataAno, SUM(salario)  \n",
        "       FROM pagamento JOIN data on data.dataPK = pagamento.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS pag(anoPag, salario)\n",
        "     JOIN \n",
        "     ( SELECT dataAno, SUM(receita)\n",
        "       FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS neg(anoNeg, receita) \n",
        "     ON anoPag = anoNeg \n",
        "ORDER BY anoPag\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------------+---------------------------+\n",
            "| Ano|Total Gasto com Salários|Total de Receitas Recebidas|\n",
            "+----+------------------------+---------------------------+\n",
            "|2016|              4442617.08|                 4614246.95|\n",
            "|2017|               9775279.8|                 7200423.35|\n",
            "|2018|            1.49355264E7|              1.159353965E7|\n",
            "|2019|           1.856766636E7|               3.53533183E7|\n",
            "|2020|           1.856766636E7|              3.022217595E7|\n",
            "+----+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP9gstSQ9XUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "945d88e8-ab51-4f6f-ecbe-7289d4a1f020"
      },
      "source": [
        "# utilizando a cláusula WHERE\n",
        "query = \"\"\"\n",
        "SELECT anoPag AS `Ano`, ROUND(salario,2) AS `Total Gasto com Salários`, ROUND(receita,2) AS `Total de Receitas Recebidas`\n",
        "FROM ( SELECT dataAno, SUM(salario) \n",
        "       FROM pagamento JOIN data on data.dataPK = pagamento.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS pag(anoPag, salario), \n",
        "     ( SELECT dataAno, SUM(receita)\n",
        "       FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "       GROUP BY dataAno\n",
        "      ) AS neg(anoNeg, receita) \n",
        "WHERE anoPag = anoNeg \n",
        "ORDER BY anoPag\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------------+---------------------------+\n",
            "| Ano|Total Gasto com Salários|Total de Receitas Recebidas|\n",
            "+----+------------------------+---------------------------+\n",
            "|2016|              4442617.08|                 4614246.95|\n",
            "|2017|               9775279.8|                 7200423.35|\n",
            "|2018|            1.49355264E7|              1.159353965E7|\n",
            "|2019|           1.856766636E7|               3.53533183E7|\n",
            "|2020|           1.856766636E7|              3.022217595E7|\n",
            "+----+------------------------+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTjo_CX1G5jy"
      },
      "source": [
        "## 5.5 Extensões ROLLUP, CUBE e GROUPING SETS \n",
        "\n",
        "**Definição:** Constrém vários níveis de agregação.\n",
        "\n",
        "- ROLLUP: criação de subtotais para as combinações dos atributos da lista de agrupamento de acordo com a ordem desses atributos. São criados n+1 níveis de agregação, sendo n o número de atributos especificados na lista de agrupamento.\n",
        "\n",
        "- CUBE: criação de subtotais para todas as combinações dos atributos da lista de agrupamento. São criados 2ˆn (2 elevado a n) níveis, sendo n o número de atributos especificados na lista de agrupamento.\n",
        "\n",
        "- GROUPING SETS: criação de subtotais para quaisquer combinações de atributos de agrupamentos. É criada a quantidade de subtotais especificados na lista de níveis de agregação desejados. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RRlVccmYhV_"
      },
      "source": [
        "\n",
        "**Exemplo de consulta com ROLLUP:** Liste as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00. Crie subtotais considerando a ordem dos atributos na lista de agrupamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwZHLSsCW0zD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39aef4b-b97c-41d8-9777-4fa2fa9a525b"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY ROLLUP (clienteSetor, clienteCidade)\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUFL8-CcYojA"
      },
      "source": [
        "**Exemplo de consulta com GROUPING SETS com semântica de ROLLUP:** Liste todas as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00. Crie subtotais considerando a ordem dos atributos na lista de agrupamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq9x3HMyPwHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa87e7f8-e549-411d-c8c2-fda1f88a00e6"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY GROUPING SETS ((clienteSetor, clienteCidade), (clienteSetor), ())\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjjDB_mtPkzw"
      },
      "source": [
        "**Exemplo de consulta com CUBE:** Liste todas as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_5lF9EVFZr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12e5efc-1f7d-442d-de8e-e5bc4f4aa0a3"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY CUBE (clienteSetor, clienteCidade)\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show(40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|               null|BELO HORIZONTE|       4379523.85|\n",
            "|               null|  CAMPO GRANDE|       3422117.05|\n",
            "|               null|      CURITIBA|       3697625.35|\n",
            "|               null|     FORTALEZA|       3391233.25|\n",
            "|               null|        MANAUS|       5234539.25|\n",
            "|               null|       MARILIA|        7289146.1|\n",
            "|               null|  PORTO ALEGRE|        4319625.7|\n",
            "|               null|        RECIFE|       4717719.45|\n",
            "|               null|RIO DE JANEIRO|    1.525596265E7|\n",
            "|               null|    SAO CARLOS|       4192741.95|\n",
            "|               null|     SAO PAULO|    2.464599965E7|\n",
            "|               null|    UBERLANDIA|        4357595.2|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ0y48oPbwiO"
      },
      "source": [
        "**Exemplo de consulta com GROUPING SETS com semântica de CUBE:** Liste todas as agregações que podem ser geradas a partir da soma da receita por setor do cliente e por cidade do cliente, para totais de receita superiores a 3.000.000,00. Crie subtotais considerando a ordem dos atributos na lista de agrupamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8oaCRpEb29W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdaec3db-d469-48a4-8972-77f8071e377d"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT clienteSetor, clientecidade, ROUND(SUM(receita),2) AS `Total de Receitas`\n",
        "FROM cliente JOIN negociacao ON cliente.clientePk = negociacao.clientePK\n",
        "GROUP BY GROUPING SETS ((clienteSetor, clienteCidade), (clienteSetor), (clienteCidade), ())\n",
        "HAVING SUM(receita) > 3000000\n",
        "ORDER BY clienteSetor, clienteCidade\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show(40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------------+\n",
            "|       clienteSetor| clienteCidade|Total de Receitas|\n",
            "+-------------------+--------------+-----------------+\n",
            "|               null|          null|     8.89837042E7|\n",
            "|               null|BELO HORIZONTE|       4379523.85|\n",
            "|               null|  CAMPO GRANDE|       3422117.05|\n",
            "|               null|      CURITIBA|       3697625.35|\n",
            "|               null|     FORTALEZA|       3391233.25|\n",
            "|               null|        MANAUS|       5234539.25|\n",
            "|               null|       MARILIA|        7289146.1|\n",
            "|               null|  PORTO ALEGRE|        4319625.7|\n",
            "|               null|        RECIFE|       4717719.45|\n",
            "|               null|RIO DE JANEIRO|    1.525596265E7|\n",
            "|               null|    SAO CARLOS|       4192741.95|\n",
            "|               null|     SAO PAULO|    2.464599965E7|\n",
            "|               null|    UBERLANDIA|        4357595.2|\n",
            "|BEBIDAS E ALIMENTOS|          null|     3.54087859E7|\n",
            "|BEBIDAS E ALIMENTOS|BELO HORIZONTE|        4206811.8|\n",
            "|BEBIDAS E ALIMENTOS|       MARILIA|        4033680.5|\n",
            "|BEBIDAS E ALIMENTOS|        RECIFE|        3899358.3|\n",
            "|BEBIDAS E ALIMENTOS|RIO DE JANEIRO|       7351629.95|\n",
            "|BEBIDAS E ALIMENTOS|     SAO PAULO|        6177945.5|\n",
            "|BEBIDAS E ALIMENTOS|    UBERLANDIA|       3283351.55|\n",
            "|            CREDITO|          null|        6621387.7|\n",
            "|              SAUDE|          null|    1.831261245E7|\n",
            "|              SAUDE|        MANAUS|       3329638.25|\n",
            "|              SAUDE|     SAO PAULO|       3963055.35|\n",
            "|         TECNOLOGIA|          null|      1.6568033E7|\n",
            "|         TECNOLOGIA|     SAO PAULO|        9200352.8|\n",
            "|          VESTUARIO|          null|    1.207288515E7|\n",
            "|          VESTUARIO|RIO DE JANEIRO|        5948448.1|\n",
            "|          VESTUARIO|     SAO PAULO|        4686200.3|\n",
            "+-------------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgV9cze8MBY3"
      },
      "source": [
        "# 6 Execução de Consultas com Foco na Tomada de Decisão\n",
        "As consultas OLAP requisitadas por usuários de sistemas de suporte à decisão usualmente requerem que várias operações OLAP sejam realizadas simultaneamente. A seguir são ilustrados exemplos de consultas OLAP que podem ser requisitadas para a tomada de decisão estratégica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcaRLxX_Jd1w"
      },
      "source": [
        "## 6.1 Consulta 1\n",
        "\n",
        "Qual é a média dos salários recebidos por nível do cargo e por sexo no ano de 2019?\n",
        "\n",
        "Para se realizar esta consulta, é necessário obter dados das tabelas de dimensão `cargo`, `funcionario` e `data`, bem como da tabela de fatos `pagamento`. A junção estrela deve ocorrer considerando as seguintes integridades referenciais:\n",
        "- `pagamento.cargoPK = cargo.cargoPK`\n",
        "- `pagamento.funcPK = funcionario.funcPK`\n",
        "- `pagamento.dataPK = data.dataPK` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeKlyc-mMt64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d0d089b-1a84-47e9-e5a8-a8cb7f4cd450"
      },
      "source": [
        "# utilizando a cláusula JOIN ... ON ...\n",
        "query = \"\"\"\n",
        "SELECT cargoNivel, funcSexo, ROUND(AVG(salario),2) AS `Média dos Salários`\n",
        "FROM pagamento JOIN data ON data.dataPK = pagamento.dataPK\n",
        "               JOIN cargo ON cargo.cargoPK = pagamento.cargoPK\n",
        "               JOIN funcionario ON funcionario.funcPK = pagamento.funcPK \n",
        "WHERE dataAno = 2019\n",
        "GROUP BY cargoNivel, funcSexo\n",
        "ORDER BY cargoNivel, funcSexo\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+------------------+\n",
            "|cargoNivel|funcSexo|Média dos Salários|\n",
            "+----------+--------+------------------+\n",
            "|    JUNIOR|       F|           2440.23|\n",
            "|    JUNIOR|       M|           2437.86|\n",
            "|     PLENO|       F|           7641.94|\n",
            "|     PLENO|       M|           6259.61|\n",
            "|    SENIOR|       F|          12994.19|\n",
            "|    SENIOR|       M|           14480.5|\n",
            "+----------+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "so-Hec1xeZHL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696f69aa-35d6-49e8-c1e7-76971db935d7"
      },
      "source": [
        "# utilizando a cláusula WHERE\n",
        "query = \"\"\"\n",
        "SELECT cargoNivel, funcSexo, ROUND(AVG(salario),2) AS `Média dos Salários`\n",
        "FROM pagamento, cargo, funcionario, data\n",
        "WHERE data.dataPK = pagamento.dataPK\n",
        "      AND cargo.cargoPK = pagamento.cargoPK\n",
        "      AND funcionario.funcPK = pagamento.funcPK\n",
        "      AND dataAno = 2019\n",
        "GROUP BY cargoNivel, funcSexo\n",
        "ORDER BY cargoNivel, funcSexo\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+------------------+\n",
            "|cargoNivel|funcSexo|Média dos Salários|\n",
            "+----------+--------+------------------+\n",
            "|    JUNIOR|       F|           2440.23|\n",
            "|    JUNIOR|       M|           2437.86|\n",
            "|     PLENO|       F|           7641.94|\n",
            "|     PLENO|       M|           6259.61|\n",
            "|    SENIOR|       F|          12994.19|\n",
            "|    SENIOR|       M|           14480.5|\n",
            "+----------+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "varyr5djDP2s"
      },
      "source": [
        "## 6.2 Consulta 2\n",
        "\n",
        "Qual o total de gastos em salários considerando os estados nos quais as equipes estão localizadas no trimestre 3 do ano de 2020? \n",
        "\n",
        "Para se realizar esta consulta, é necessário obter dados das tabelas de dimensão `equipe` e `data`, bem como da tabela de fatos `pagamento`. A junção estrela deve ocorrer considerando as seguintes integridades referenciais:\n",
        "- `pagamento.dataPK = data.dataPK`\n",
        "- `pagamento.equipePK = equipe.equipePK`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSgE7xtPkGYf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9082f4-fd07-4d75-dc83-71b332dd5280"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT filialEstadoNome, ROUND(SUM(salario),2) AS Total\n",
        "FROM pagamento JOIN data ON data.dataPK = pagamento.dataPK \n",
        "               JOIN equipe ON equipe.equipePK = pagamento.equipePK\n",
        "WHERE dataAno = 2019\n",
        "      AND dataTrimestre = 3\n",
        "GROUP BY filialEstadoNome\n",
        "ORDER BY Total \n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------+\n",
            "|  filialEstadoNome|     Total|\n",
            "+------------------+----------+\n",
            "|        PERNAMBUCO| 438121.26|\n",
            "|MATO GROSSO DO SUL|1013857.74|\n",
            "|    RIO DE JANEIRO|1258479.57|\n",
            "|         SAO PAULO|1931458.02|\n",
            "+------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAqNkANBOZSI"
      },
      "source": [
        "## 6.3 Consulta 3\n",
        "\n",
        "Qual o custo/benefício das equipes quando analisado o semestre 1 do ano de 2020?\n",
        "\n",
        "A idea da consulta é relacionar os gastos em salários e os ganhos em receitas considerando cada equipe e o período especificado. Portanto, para se realizar essa consulta, é necessário obter dados das tabelas de dimensão `equipe` e `data`, bem como das tabelas de fatos `pagamento` e `negociacao`. \n",
        "\n",
        " A junção estrela deve ocorrer considerando as seguintes integridades referenciais:\n",
        "- `pagamento.dataPK = data.dataPK`\n",
        "- `pagamento.equipePK = equipe.equipe.PK`\n",
        "- `negociacao.dataPK = data.dataPK`\n",
        "- `negociacao.equipePK = equipe.equipe.PK`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMyeJDwisUgu"
      },
      "source": [
        "Uma observação muito importante refere-se ao fato que, para evitar dubiedade nas respostas, elas devem ser feitas sempre considerando a chave primária, desde que a chave primária identifica univocamente cada tupla. Depois de ser resolvida a consulta em termos da chave primária, então deve ser obtido os demais atributos a serem exibidos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MybQ9xten5-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fab79a-e771-4857-f1a8-fd25bdee2d8a"
      },
      "source": [
        "query = \"\"\"\n",
        "-- obtendo os dados a serem exibidos na resposta\n",
        "SELECT equipeNome, filialNome, ROUND(Lucro,2)\n",
        "FROM equipe,\n",
        "(\n",
        "   SELECT pag.equipePK AS retornaEquipePK, (TotalReceita - TotalSalario) AS Lucro\n",
        "   FROM ( \n",
        "        -- investigando os gastos em salarios de cada equipe no último semestre deste ano \n",
        "        SELECT equipePK, SUM(salario) AS TotalSalario\n",
        "        FROM pagamento JOIN data ON data.dataPK = pagamento.dataPK\n",
        "        WHERE dataSemestre = 1 \n",
        "              AND dataAno = 2020\n",
        "        GROUP BY equipePK \n",
        "        ORDER BY equipePK \n",
        "        ) AS pag,  \n",
        "        (\n",
        "        -- investigando os ganhos em receitas de cada equipe no último semestre deste ano   \n",
        "        SELECT equipePK, SUM(receita) AS TotalReceita\n",
        "        FROM negociacao JOIN data ON data.dataPK = negociacao.dataPK\n",
        "        WHERE dataSemestre = 1 \n",
        "              AND dataAno = 2020\n",
        "        GROUP BY equipePK \n",
        "        ORDER BY equipePK\n",
        "        ) AS neg\n",
        "   WHERE pag.equipePK = neg.equipePK\n",
        "   ) AS parte\n",
        "WHERE equipe.equipePK = parte.retornaEquipePK\n",
        "ORDER BY Lucro DESC\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------------+---------------+\n",
            "|    equipeNome|          filialNome|round(Lucro, 2)|\n",
            "+--------------+--------------------+---------------+\n",
            "|BI & ANALYTICS|SAO PAULO - AV. P...|     4054890.24|\n",
            "|BI & ANALYTICS|     RECIFE - CENTRO|     3788503.18|\n",
            "| APP - DESKTOP|RIO DE JANEIRO - ...|      278013.26|\n",
            "|  APP - MOBILE|SAO PAULO - AV. P...|      151160.49|\n",
            "| APP - DESKTOP|SAO PAULO - AV. P...|       99579.85|\n",
            "+--------------+--------------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}